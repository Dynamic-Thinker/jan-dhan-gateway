"""
Jan-Dhan Gateway - Production-Grade ML Model Training
Real-world implementation with proper data science practices
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import pickle
import os
from datetime import datetime, timedelta
import random
import warnings
warnings.filterwarnings('ignore')

class ProductionModelTrainer:
    """
    Production-grade ML training pipeline
    Follows real-world data science best practices
    """
    
    def __init__(self, registry_path: str, models_dir: str = '../models'):
        self.registry_path = registry_path
        self.models_dir = models_dir
        os.makedirs(models_dir, exist_ok=True)
        
        print("="*70)
        print("ðŸŽ“ JAN-DHAN GATEWAY - PRODUCTION ML TRAINING PIPELINE")
        print("="*70)
        
        # Load registry data
        print("\nðŸ“Š Step 1: Loading Registry Data...")
        self.df = pd.read_excel(registry_path)
        print(f"âœ“ Loaded {len(self.df)} citizen records")
        print(f"âœ“ Columns: {list(self.df.columns)}")
        
        # Analyze data distribution
        self._analyze_data_distribution()
    
    def _analyze_data_distribution(self):
        """Analyze actual data patterns from registry"""
        print("\nðŸ“ˆ Step 2: Analyzing Data Distribution...")
        
        print("\nClaim Count Distribution:")
        print(self.df['Claim_Count'].describe())
        
        print("\nScheme Distribution:")
        print(self.df['Scheme_Eligibility'].value_counts())
        
        print("\nAccount Status Distribution:")
        print(self.df['Account_Status'].value_counts())
        
        print("\nIncome Tier Distribution:")
        print(self.df['Income_Tier'].value_counts())
    
    def generate_realistic_transactions(self, num_transactions: int = 2000):
        """
        Generate realistic transactions using ACTUAL registry patterns
        """
        print(f"\nðŸ”„ Step 3: Generating {num_transactions} Realistic Transactions...")
        
        transactions = []
        
        # Analyze actual claim patterns
        avg_claims = self.df['Claim_Count'].mean()
        max_claims = self.df['Claim_Count'].max()
        
        print(f"  - Average claims in registry: {avg_claims:.2f}")
        print(f"  - Maximum claims in registry: {max_claims}")
        
        for i in range(num_transactions):
            # Select random citizen from actual registry
            citizen = self.df.sample(1).iloc[0]
            
            # Decide fraud based on realistic probabilities (5% fraud rate)
            is_fraud = random.random() < 0.05
            
            if is_fraud:
                # FRAUD PATTERNS (based on real-world fraud indicators):
                # 1. Claim count exceeds maximum + 2
                # 2. Very recent claims (0-5 days)
                # 3. Suspicious timing patterns
                claim_count = random.randint(int(max_claims) + 1, int(max_claims) + 4)
                days_since_claim = random.randint(0, 5)
                
                # 30% chance of off-hours
                if random.random() < 0.3:
                    hour = random.choice([0, 1, 2, 3, 4, 5, 23])
                else:
                    hour = random.randint(6, 22)
                
                # Weekend claims slightly more common in fraud
                day_of_week = random.choice([0, 1, 2, 3, 4, 5, 5, 6, 6])
                
            else:
                # NORMAL PATTERNS (based on actual registry):
                # 1. Claim count within normal range (0 to max)
                # 2. Reasonable gaps between claims (30-180 days)
                # 3. Business hours (8am-6pm)
                # 4. Weekdays more common
                claim_count = random.randint(0, int(max_claims))
                days_since_claim = random.randint(30, 180)
                hour = random.randint(8, 18)  # Business hours
                day_of_week = random.choice([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5])  # Weekday bias
            
            # Get scheme amount from registry
            scheme = citizen['Scheme_Eligibility']
            amounts = {'Pension': 3000, 'Health': 5000, 'Food': 2000}
            amount = amounts.get(scheme, 3000)
            
            # Calculate frequency score
            frequency_score = claim_count / max(days_since_claim, 1)
            
            # Additional realistic features
            is_suspended = 1 if citizen['Account_Status'] == 'Suspended' else 0
            is_blacklisted = 1 if citizen['Account_Status'] == 'Blacklisted' else 0
            
            transaction = {
                'citizen_id': citizen['Citizen_ID'],
                'claim_count': claim_count,
                'days_since_claim': days_since_claim,
                'amount': amount,
                'hour': hour,
                'day_of_week': day_of_week,
                'frequency_score': frequency_score,
                'is_suspended': is_suspended,
                'is_blacklisted': is_blacklisted,
                'is_fraud': 1 if is_fraud else 0
            }
            
            transactions.append(transaction)
        
        df_transactions = pd.DataFrame(transactions)
        
        # Save synthetic data
        synthetic_path = os.path.join(self.models_dir, 'realistic_transactions.csv')
        df_transactions.to_csv(synthetic_path, index=False)
        
        fraud_count = (df_transactions['is_fraud'] == 1).sum()
        normal_count = (df_transactions['is_fraud'] == 0).sum()
        
        print(f"âœ“ Generated {num_transactions} transactions")
        print(f"  - Normal: {normal_count} ({normal_count/num_transactions*100:.1f}%)")
        print(f"  - Fraudulent: {fraud_count} ({fraud_count/num_transactions*100:.1f}%)")
        print(f"âœ“ Saved to: {synthetic_path}")
        
        return df_transactions
    
    def train_fraud_detection_model(self, df_transactions):
        """
        Train Isolation Forest with PROPER calibration
        """
        print("\nðŸ¤– Step 4: Training Fraud Detection Model...")
        
        # Feature engineering
        features = [
            'claim_count', 'days_since_claim', 'amount',
            'hour', 'day_of_week', 'frequency_score',
            'is_suspended', 'is_blacklisted'
        ]
        
        X = df_transactions[features].values
        y = df_transactions['is_fraud'].values
        
        print(f"  - Feature count: {len(features)}")
        print(f"  - Training samples: {len(X)}")
        
        # Proper feature scaling
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Train Isolation Forest with proper contamination
        contamination = y.mean()  # Use actual fraud rate
        print(f"  - Contamination rate: {contamination:.3f}")
        
        model = IsolationForest(
            contamination=contamination,
            random_state=42,
            n_estimators=150,
            max_samples=256,
            bootstrap=True,
            n_jobs=-1
        )
        
        model.fit(X_scaled)
        
        # Evaluate with proper threshold calibration
        anomaly_scores = model.score_samples(X_scaled)
        predictions = model.predict(X_scaled)
        
        # Find optimal threshold using actual fraud labels
        # Convert anomaly scores to probabilities
        min_score = anomaly_scores.min()
        max_score = anomaly_scores.max()
        
        # Normalize scores to 0-1 range
        normalized_scores = (anomaly_scores - min_score) / (max_score - min_score)
        # Invert so high score = high fraud probability
        fraud_probs = 1 - normalized_scores
        
        # Convert predictions to binary (1 = fraud, 0 = normal)
        predicted_fraud = (predictions == -1).astype(int)
        
        # Calculate metrics
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        
        accuracy = accuracy_score(y, predicted_fraud)
        precision = precision_score(y, predicted_fraud, zero_division=0)
        recall = recall_score(y, predicted_fraud, zero_division=0)
        f1 = f1_score(y, predicted_fraud, zero_division=0)
        
        print(f"\nðŸ“Š Model Performance:")
        print(f"  - Accuracy:  {accuracy:.3f}")
        print(f"  - Precision: {precision:.3f}")
        print(f"  - Recall:    {recall:.3f}")
        print(f"  - F1-Score:  {f1:.3f}")
        
        # Confusion Matrix
        tn, fp, fn, tp = confusion_matrix(y, predicted_fraud).ravel()
        print(f"\nðŸ“ˆ Confusion Matrix:")
        print(f"  - True Negatives:  {tn}")
        print(f"  - False Positives: {fp}")
        print(f"  - False Negatives: {fn}")
        print(f"  - True Positives:  {tp}")
        
        # Save model and scaler with calibration info
        model_data = {
            'model': model,
            'scaler': scaler,
            'min_score': min_score,
            'max_score': max_score,
            'features': features
        }
        
        model_path = os.path.join(self.models_dir, 'fraud_model_calibrated.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"\nâœ“ Model saved: {model_path}")
        
        return model, scaler, min_score, max_score
    
    def train_supervised_fraud_model(self, df_transactions):
        """
        Train Random Forest classifier for comparison
        """
        print("\nðŸ¤– Step 5: Training Supervised Fraud Model (Random Forest)...")
        
        features = [
            'claim_count', 'days_since_claim', 'amount',
            'hour', 'day_of_week', 'frequency_score',
            'is_suspended', 'is_blacklisted'
        ]
        
        X = df_transactions[features].values
        y = df_transactions['is_fraud'].values
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Train Random Forest
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=20,
            min_samples_leaf=10,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        
        model.fit(X_train_scaled, y_train)
        
        # Evaluate
        train_score = model.score(X_train_scaled, y_train)
        test_score = model.score(X_test_scaled, y_test)
        
        print(f"  - Training accuracy: {train_score:.3f}")
        print(f"  - Testing accuracy:  {test_score:.3f}")
        
        # Feature importance
        importances = model.feature_importances_
        print(f"\nðŸ“Š Feature Importance:")
        for feat, imp in sorted(zip(features, importances), key=lambda x: x[1], reverse=True):
            print(f"  - {feat:20s}: {imp:.3f}")
        
        # Save supervised model
        supervised_model_data = {
            'model': model,
            'scaler': scaler,
            'features': features
        }
        
        model_path = os.path.join(self.models_dir, 'fraud_model_supervised.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(supervised_model_data, f)
        
        print(f"âœ“ Supervised model saved: {model_path}")
        
        return model, scaler
    
    def train_ledger_tamper_model(self):
        """Train ledger tamper detection with realistic thresholds"""
        print("\nðŸ¤– Step 6: Training Ledger Tamper Detection Model...")
        
        # Generate realistic ledger data
        ledger_entries = []
        
        for i in range(1000):
            is_tampered = random.random() < 0.03  # 3% tamper rate
            
            if is_tampered:
                # Tampered patterns
                hash_valid = random.choice([0, 0, 0, 1])  # 75% invalid hash
                timestamp_gap = random.randint(1000, 50000)
                checksum_valid = random.choice([0, 0, 1])  # 66% invalid
                field_count = random.randint(3, 7)
            else:
                # Valid patterns
                hash_valid = 1
                timestamp_gap = random.randint(1, 500)
                checksum_valid = 1
                field_count = 8
            
            ledger_entries.append({
                'hash_valid': hash_valid,
                'timestamp_gap': timestamp_gap,
                'checksum_valid': checksum_valid,
                'field_count': field_count,
                'is_tampered': is_tampered
            })
        
        df_ledger = pd.DataFrame(ledger_entries)
        
        # Save
        ledger_path = os.path.join(self.models_dir, 'realistic_ledger.csv')
        df_ledger.to_csv(ledger_path, index=False)
        print(f"âœ“ Generated {len(df_ledger)} ledger entries")
        
        # Train model
        features = ['hash_valid', 'timestamp_gap', 'checksum_valid', 'field_count']
        X = df_ledger[features].values
        y = df_ledger['is_tampered'].values
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=8,
            class_weight='balanced',
            random_state=42
        )
        
        model.fit(X_train, y_train)
        
        train_score = model.score(X_train, y_train)
        test_score = model.score(X_test, y_test)
        
        print(f"  - Training accuracy: {train_score:.3f}")
        print(f"  - Testing accuracy:  {test_score:.3f}")
        
        # Save
        model_path = os.path.join(self.models_dir, 'ledger_tamper_model_calibrated.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        
        print(f"âœ“ Ledger tamper model saved: {model_path}")
        
        return model
    
    def train_all_models(self):
        """Complete training pipeline"""
        print("\n" + "="*70)
        print("ðŸš€ STARTING COMPLETE TRAINING PIPELINE")
        print("="*70)
        
        # Generate realistic data
        df_transactions = self.generate_realistic_transactions(num_transactions=2000)
        
        # Train unsupervised model (Isolation Forest)
        fraud_model, fraud_scaler, min_score, max_score = self.train_fraud_detection_model(df_transactions)
        
        # Train supervised model (Random Forest) for comparison
        supervised_model, supervised_scaler = self.train_supervised_fraud_model(df_transactions)
        
        # Train ledger tamper model
        ledger_model = self.train_ledger_tamper_model()
        
        print("\n" + "="*70)
        print("âœ… ALL MODELS TRAINED SUCCESSFULLY!")
        print("="*70)
        
        print("\nðŸ“ Generated Files:")
        print(f"  1. {self.models_dir}/fraud_model_calibrated.pkl")
        print(f"  2. {self.models_dir}/fraud_model_supervised.pkl")
        print(f"  3. {self.models_dir}/ledger_tamper_model_calibrated.pkl")
        print(f"  4. {self.models_dir}/realistic_transactions.csv")
        print(f"  5. {self.models_dir}/realistic_ledger.csv")
        
        print("\nðŸŽ¯ Next Steps:")
        print("  1. Run: python test_models_production.py")
        print("  2. Verify model performance")
        print("  3. Integrate with Flask app")


if __name__ == '__main__':
    REGISTRY_PATH = '../data/jan_dhan_registry_advanced.xlsx'
    MODELS_DIR = '../models'
    
    if not os.path.exists(REGISTRY_PATH):
        print(f"âŒ ERROR: Registry not found at {REGISTRY_PATH}")
        exit(1)
    
    trainer = ProductionModelTrainer(REGISTRY_PATH, MODELS_DIR)
    trainer.train_all_models()
    
    print("\nâœ… Training complete! Run test_models_production.py to verify.")